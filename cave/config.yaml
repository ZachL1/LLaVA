experiment:
  project: cave_vae_project
  name: cave_flexible
  output_dir: cave_flexible
  max_train_examples: 11829284
  save_every: 10000
  eval_every: 5000
  generate_every: 5000
  log_every: 100
  log_grad_norm_every: 1000
  resume: true
  init_weight: ''
  logging_dir: cave_flexible/logs
model:
  use_vae: true
  use_diffusion: false
  sd3_model_path: ./cave/sd35/models/sd3.5_medium.safetensors
  vae_path: null
  diffusion_shift: 3.0
  image_size: 256
  use_text_context: false
  text_embed_dim: 768
  encoder:
    input_size: 32
    patch_size: 2
    in_channels: 16
    depth: 24
    mlp_ratio: 4.0
    learn_sigma: false
    adm_in_channels: null
    context_embedder_config: null
    register_length: 0
    rmsnorm: false
    scale_mod_only: false
    swiglu: false
    out_channels: null
    pos_embed_scaling_factor: null
    pos_embed_offset: null
    pos_embed_max_size: 16
    num_patches: 256
    qk_norm: null
    x_block_self_attn_layers: []
    qkv_bias: true
    dtype: null
    device: null
    verbose: false
    max_context_tokens: 256
    min_context_tokens: 1
    default_context_tokens: 32
  decoder:
    input_size: 32
    patch_size: 2
    in_channels: 16
    depth: 24
    mlp_ratio: 4.0
    learn_sigma: false
    adm_in_channels: null
    context_embedder_config: null
    register_length: 0
    rmsnorm: false
    scale_mod_only: false
    swiglu: false
    out_channels: null
    pos_embed_scaling_factor: null
    pos_embed_offset: null
    pos_embed_max_size: 16
    num_patches: 256
    qk_norm: null
    x_block_self_attn_layers: []
    qkv_bias: true
    dtype: null
    device: null
    verbose: false
losses:
  reconstruction_weight: 1.0
dataset:
  params:
    train_shards_path_or_url: /mnt/bn/kgvanasgcparnold/annan/ImageNet_winter21_wd/train-{000000..002957}.tar
    eval_shards_path_or_url: /mnt/bn/kgvanasgcparnold/annan/ImageNet_winter21_wd/val-{000000..000331}.tar
    num_workers_per_gpu: 12
  preprocessing:
    resize_shorter_edge: 256
    crop_size: 256
    random_crop: true
    random_flip: true
optimizer:
  name: adamw
  params:
    learning_rate: 5.0e-05
    beta1: 0.9
    beta2: 0.99
    weight_decay: 0.0001
lr_scheduler:
  scheduler: cosine
  params:
    learning_rate: ${optimizer.params.learning_rate}
    warmup_steps: 10000
    end_lr: 5.0e-06
training:
  gradient_accumulation_steps: 4
  per_gpu_batch_size: 32
  mixed_precision: fp16
  enable_tf32: true
  enable_wandb: true
  use_ema: false
  seed: 42
  max_train_steps: 1000000
  num_generated_images: 2
  max_grad_norm: 1.0
  deepspeed_config_file: configs/deepspeed/ds_z2_config.json
validation:
  sample_reconstruction: true
  sample_diffusion: false
  num_samples: 16
--local_rank: 0
config: configs/training/cave_vae_dev.yaml
